{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Example usage of the `torchTextClassifiers` library\n",
    "\n",
    "*Warning*\n",
    "\n",
    "*`torchTextClassifiers` library is still under active development. Have a\n",
    "regular look to <https://github.com/inseefrlab/torchTextClassifiers> for\n",
    "latest information.*\n",
    "\n",
    "To install package, you can run the following snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchTextClassifiers import ModelConfig, TrainingConfig, torchTextClassifiers\n",
    "from torchTextClassifiers.dataset import TextClassificationDataset\n",
    "from torchTextClassifiers.model import TextClassificationModel, TextClassificationModule\n",
    "from torchTextClassifiers.model.components import (\n",
    "    AttentionConfig,\n",
    "    CategoricalVariableNet,\n",
    "    ClassificationHead,\n",
    "    TextEmbedder,\n",
    "    TextEmbedderConfig,\n",
    ")\n",
    "from torchTextClassifiers.tokenizers import HuggingFaceTokenizer, WordPieceTokenizer\n",
    "from torchTextClassifiers.utilities.plot_explainability import (\n",
    "    map_attributions_to_char,\n",
    "    map_attributions_to_word,\n",
    "    plot_attributions_at_char,\n",
    "    plot_attributions_at_word,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Load and preprocess data\n",
    "\n",
    "In that guide, we propose to illustrate main package functionalities\n",
    "using that `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"https://minio.lab.sspcloud.fr/projet-ape/data/08112022_27102024/naf2008/split/df_train.parquet\")\n",
    "df = df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def categorize_surface(\n",
    "    df: pd.DataFrame, surface_feature_name: int, like_sirene_3: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Categorize the surface of the activity.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to categorize.\n",
    "        surface_feature_name (str): Name of the surface feature.\n",
    "        like_sirene_3 (bool): If True, categorize like Sirene 3.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with a new column \"surf_cat\".\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy[surface_feature_name] = df_copy[surface_feature_name].replace(\"nan\", np.nan)\n",
    "    df_copy[surface_feature_name] = df_copy[surface_feature_name].astype(float)\n",
    "    # Check surface feature exists\n",
    "    if surface_feature_name not in df.columns:\n",
    "        raise ValueError(f\"Surface feature {surface_feature_name} not found in DataFrame.\")\n",
    "    # Check surface feature is a float variable\n",
    "    if not (pd.api.types.is_float_dtype(df_copy[surface_feature_name])):\n",
    "        raise ValueError(f\"Surface feature {surface_feature_name} must be a float variable.\")\n",
    "\n",
    "    if like_sirene_3:\n",
    "        # Categorize the surface\n",
    "        df_copy[\"surf_cat\"] = pd.cut(\n",
    "            df_copy[surface_feature_name],\n",
    "            bins=[0, 120, 400, 2500, np.inf],\n",
    "            labels=[\"1\", \"2\", \"3\", \"4\"],\n",
    "        ).astype(str)\n",
    "    else:\n",
    "        # Log transform the surface\n",
    "        df_copy[\"surf_log\"] = np.log(df[surface_feature_name])\n",
    "\n",
    "        # Categorize the surface\n",
    "        df_copy[\"surf_cat\"] = pd.cut(\n",
    "            df_copy.surf_log,\n",
    "            bins=[0, 3, 4, 5, 12],\n",
    "            labels=[\"1\", \"2\", \"3\", \"4\"],\n",
    "        ).astype(str)\n",
    "\n",
    "    df_copy[surface_feature_name] = df_copy[\"surf_cat\"].replace(\"nan\", \"0\")\n",
    "    df_copy[surface_feature_name] = df_copy[surface_feature_name].astype(int)\n",
    "    df_copy = df_copy.drop(columns=[\"surf_log\", \"surf_cat\"], errors=\"ignore\")\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def clean_and_tokenize_df(\n",
    "    df,\n",
    "    categorical_features=[\"CJ\", \"NAT\", \"TYP\", \"CRT\"],\n",
    "    text_feature=\"libelle_processed\",\n",
    "    label_col=\"apet_finale\",\n",
    "):\n",
    "    df.fillna(\"nan\", inplace=True)\n",
    "    les = []\n",
    "    for col in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        les.append(le)\n",
    "\n",
    "    df = categorize_surface(df, \"SRF\", like_sirene_3=True)\n",
    "    df = df[[text_feature,  \"CJ\", \"NAT\", \"TYP\", \"SRF\", \"CRT\", label_col]]\n",
    "\n",
    "    return df, les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [ \"CJ\", \"NAT\", \"TYP\", \"SRF\", \"CRT\"]\n",
    "text_feature = \"libelle\"\n",
    "y = \"apet_finale\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Right now, the model requires the label (variable y) to be a numerical\n",
    "variable. If the label variable is a text variable, we recommend using\n",
    "Scikit Learn’s\n",
    "[LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
    "to convert into a numeric variable. Using that function will give user\n",
    "the possibility to get back labels from the encoder after running\n",
    "predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df[\"apet_finale\"] = encoder.fit_transform(df[\"apet_finale\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "The function `clean_and_tokenize_df` requires special `DataFrame`\n",
    "formatting:\n",
    "\n",
    "-   First column contains the processed text (str)\n",
    "-   Next ones contain the “encoded” categorical (discrete) variables in\n",
    "    int format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = clean_and_tokenize_df(df, text_feature=\"libelle\")\n",
    "X = df[[\"libelle\", \"CJ\", \"NAT\", \"TYP\", \"CRT\", \"SRF\"]].values\n",
    "y = df[\"apet_finale\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Splitting in train-test sets\n",
    "\n",
    "As usual in a learning approach, you need to break down your data into\n",
    "learning and test/validation samples to obtain robust performance\n",
    "statistics.\n",
    "This work is the responsibility of the package’s users. Please make sure that np.max(y_train) == len(np.unique(y_train))-1 (i.e. your labels are well encoded, in a consecutive manner, starting from 0), and that all the possible labels appear at least once in the training set.\n",
    "\n",
    "We provide the function stratified_train_test_split to match these requirements here.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = X_train[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = HuggingFaceTokenizer.load_from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "tokenizer.tokenize(text[0]).input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordPieceTokenizer(vocab_size=5000, output_dim=125)\n",
    "tokenizer.train(text)\n",
    "tokenizer.tokenize(text[:256]).input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Consider each component indepedently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "padding_idx = tokenizer.padding_idx\n",
    "\n",
    "embedding_dim = 96\n",
    "n_layers = 1\n",
    "n_head = 4\n",
    "n_kv_head = n_head\n",
    "sequence_len = tokenizer.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_config = AttentionConfig(\n",
    "    n_layers=n_layers,\n",
    "    n_head=n_head,\n",
    "    n_kv_head=n_kv_head,\n",
    "    sequence_len=sequence_len,\n",
    ")\n",
    "\n",
    "text_embedder_config = TextEmbedderConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    padding_idx=padding_idx,\n",
    "    attention_config=attention_config,\n",
    ")\n",
    "\n",
    "\n",
    "text_embedder = TextEmbedder(\n",
    "    text_embedder_config=text_embedder_config,\n",
    ")\n",
    "text_embedder.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 1:].max(axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vocab_sizes = (X[:, 1:].max(axis=0) + 1).tolist()\n",
    "categorical_embedding_dims = 25\n",
    "\n",
    "categorical_var_net = CategoricalVariableNet(\n",
    "    categorical_vocabulary_sizes=categorical_vocab_sizes,\n",
    "    categorical_embedding_dims=categorical_embedding_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = int(y.max() + 1)\n",
    "expected_input_dim = embedding_dim + categorical_var_net.output_dim\n",
    "classification_head = ClassificationHead(\n",
    "    input_dim=expected_input_dim,\n",
    "    num_classes=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassificationModel(\n",
    "    text_embedder=text_embedder,\n",
    "    categorical_variable_net=categorical_var_net,\n",
    "    classification_head=classification_head,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "module = TextClassificationModule(\n",
    "    model=model,\n",
    "    loss=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    "    scheduler=None,\n",
    "    scheduler_params=None,\n",
    "    scheduler_interval=\"epoch\",\n",
    ")\n",
    "module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Using the wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    embedding_dim=embedding_dim,\n",
    "    categorical_vocabulary_sizes=categorical_vocab_sizes,\n",
    "    categorical_embedding_dims=categorical_embedding_dims,\n",
    "    num_classes=num_classes,\n",
    "    attention_config=attention_config,\n",
    ")\n",
    "\n",
    "training_config = TrainingConfig(\n",
    "    lr=1e-3,\n",
    "    batch_size=256,\n",
    "    num_epochs=10,\n",
    ")\n",
    "\n",
    "ttc = torchTextClassifiers(\n",
    "    tokenizer=tokenizer,\n",
    "    model_config=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(X_train[:256, 0].tolist()).input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttc.train(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    training_config=training_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttc.pytorch_model.eval().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "yyy = ttc.predict(X_test[:10], top_k=top_k, explain=True)\n",
    "\n",
    "text_idx = 0\n",
    "text = X_test[text_idx, 0]\n",
    "offsets = yyy[\"offset_mapping\"][text_idx]  # seq_len, 2\n",
    "attributions = yyy[\"attributions\"][text_idx]  # top_k, seq_len\n",
    "word_ids = yyy[\"word_ids\"][text_idx]  # seq_len\n",
    "predictions = yyy[\"prediction\"][text_idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attributions = map_attributions_to_word(attributions, word_ids)\n",
    "char_attributions = map_attributions_to_char(attributions, offsets, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.inverse_transform(np.array([predictions]).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = plot_attributions_at_char(\n",
    "    text=text,\n",
    "    attributions_per_char=char_attributions,\n",
    "    titles = list(map(lambda x: f\"Attributions for code {x}\", encoder.inverse_transform(np.array([predictions]).reshape(-1)).tolist())),\n",
    ")\n",
    "figshow(all_plots[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = plot_attributions_at_word(\n",
    "    text=text,\n",
    "    attributions_per_word=word_attributions,\n",
    "    titles = list(map(lambda x: f\"Attributions for code {x}\", encoder.inverse_transform(np.array([predictions]).reshape(-1)).tolist())),\n",
    ")\n",
    "figshow(all_plots[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
